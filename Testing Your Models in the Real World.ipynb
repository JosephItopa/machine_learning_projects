{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Testing Your Models in the Real World\n",
    "How do you know that your models will do a good job making predictions on new, unseen data?  \n",
    "\n",
    "This lab will discuss the fundamentals of splitting your data into training, validation and test data sets and demonstrate the dangers of overreliance on training data to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Import Data\n",
    "This lab uses the [Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) from [Kaggle](https://www.kaggle.com).  \n",
    "\n",
    "In order to interact with the data in python, you will need to import the CSV into a *pandas* [dataframe](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe).  The [pandas](https://pandas.pydata.org/) package is useful for manipulating and analyzing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53882</td>\n",
       "      <td>Male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.4</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10434</td>\n",
       "      <td>Female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27419</td>\n",
       "      <td>Female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>76.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60491</td>\n",
       "      <td>Female</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>58.57</td>\n",
       "      <td>24.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "5  56669    Male  81.0             0              0          Yes   \n",
       "6  53882    Male  74.0             1              1          Yes   \n",
       "7  10434  Female  69.0             0              0           No   \n",
       "8  27419  Female  59.0             0              0          Yes   \n",
       "9  60491  Female  78.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "5        Private          Urban             186.21  29.0  formerly smoked   \n",
       "6        Private          Rural              70.09  27.4     never smoked   \n",
       "7        Private          Urban              94.39  22.8     never smoked   \n",
       "8        Private          Rural              76.15   NaN          Unknown   \n",
       "9        Private          Urban              58.57  24.2          Unknown   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "#Read in stroke data\n",
    "stroke_data = pd.read_csv('data_files/model_testing/healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "#Display first 10 records of the data\n",
    "stroke_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some summary statistics about the **stroke** column, which is what you will be trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5,110 records in the stroke dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4861</td>\n",
       "      <td>0.951272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count   Percent\n",
       "stroke                 \n",
       "0        4861  0.951272\n",
       "1         249  0.048728"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total records in the dataset\n",
    "total_records = stroke_data.shape[0]\n",
    "print('There are {:,} records in the stroke dataset.'.format(total_records))\n",
    "\n",
    "summary = pd.DataFrame(stroke_data.groupby('stroke').size()).rename(columns={0:'Count'})\n",
    "summary['Percent'] = summary['Count'] / total_records\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninety-five percent of the patients in this data did not have a stroke.  Therefore, you could build a model that always predicts \"no stroke\" and have 95% accuracy.  This is not, however, what you want to do, since the goal is to accurately predict when a patient **does** have a stroke.\n",
    "\n",
    "There are a number of techniques to deal with [unbalanced datasets](https://medium.com/strands-tech-corner/unbalanced-datasets-what-to-do-144e0552d9cd) such as this one.  For this lab, you will use the **true positive rate** to assess the performance of your predictions.\n",
    "<center>\n",
    "    $\\text{True Positive Rate} = \\frac{TP}{TP+FN}$\n",
    "</center>  \n",
    "\n",
    "where \n",
    "* $TP$ is the number of true positive predictions (actual value = stroke; predicted value = stroke)\n",
    "* $FN$ is the number of false negative predictions (actual value = stroke; predicted value = no stroke)\n",
    "\n",
    "This value, also called [sensitivity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) or [recall](https://en.wikipedia.org/wiki/Precision_and_recall), measures how well a model is at capturing actual stroke cases.  \n",
    "\n",
    "Assuming medical interventions are relatively cheap (i.e., recommending weight loss or exercise to a patient in danger of a stroke), it is better to have the occasional false positive than miss patients at high risk for strokes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that you know how you will evaluate the predictions from your model, how can you know if your model does well predicting strokes in the real world?  The goal is to build a model that identifies factors indicating a high likelihood of having a stroke, so interventions can hopefully prevent the stroke *before* it happens.  \n",
    "\n",
    "This being the case, you need to evaluate correct predictions on data that the model has never seen before.  This can be done by splitting your data into a training dataset (to use for training and evaluating the model as it is being built) and a test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup\n",
    "Before you can do any modeling, categorical variables that will be used to predict strokes need to be converted to [dummy variables](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)).  \n",
    "\n",
    "You also need to replace missing data in the BMI column.  For this lab, you will simply use the average BMI to replace the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender\n",
    "#First, to make things easier, remove the one \"other\" gender value.\n",
    "stroke_data = stroke_data[stroke_data['gender'] != 'Other']\n",
    "#Add new column 'male': 1 = male; 0 = female\n",
    "stroke_data['male'] = pd.get_dummies(stroke_data['gender'], drop_first=True)\n",
    "\n",
    "#Residence Type\n",
    "#Add new column 'urban': 1 = urban; 0 = rural\n",
    "stroke_data['urban'] = pd.get_dummies(stroke_data['Residence_type'], drop_first=True)\n",
    "\n",
    "#Married\n",
    "stroke_data['married'] = pd.get_dummies(stroke_data['ever_married'], drop_first=True)\n",
    "\n",
    "#Smoking Status\n",
    "smoking_dummies = pd.get_dummies(stroke_data['smoking_status'], drop_first=True)\n",
    "stroke_data = pd.concat([stroke_data, smoking_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Missing BMI with average BMI\n",
    "bmi_average = stroke_data['bmi'].mean()\n",
    "stroke_data['bmi'] = stroke_data['bmi'].fillna(bmi_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Create a Test Dataset\n",
    "You will now split your dataset into two datasets:\n",
    "* Training Data: Used to train your model to identify important predictors of stroke\n",
    "* Test Data: Reserved to evaluate the model on new, unseen data\n",
    "\n",
    "The [scikit-learn](https://scikit-learn.org/stable/index.html) package in python has many tools for machine learning, including data preparation tools.  For this lab, you will be using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.  \n",
    "\n",
    "Inputs to *train_test_split*:\n",
    " * **arrays**: This is where you enter one or more arrays: the entire dataset including the output or two separate arrays (X array (predictors) and y array (output) variable).  If you enter two arrays, the number of rows in the X and y arrays must be the same and the indexes must align the data.\n",
    " * **test_size**: Value between 0 and 1 that indicates the percentage of data to be reserved for the test dataset (defaults to 0.25 if train_size is None).\n",
    " * **train_size**: Value between 0 and 1 that indicates the percentage of data to be used for the training dataset (complement of test_size if test_size is set and this value is None).\n",
    " * **random_state**: Seed value for randomizing the data split.\n",
    " * **shuffle**: Whether to shuffle the data before splitting (defaults to True).\n",
    " * **stratify**: Output field to use for [stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling)  (defaults to None).\n",
    " \n",
    "Since your dataset has unbalanced output classes, you want to be sure to use the **stratify** option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train_test_split function from scikit-learn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(stroke_data,train_size=0.8,stratify=stroke_data['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4,087 records in the training dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3888</td>\n",
       "      <td>0.951309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>0.048691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count   Percent\n",
       "stroke                 \n",
       "0        3888  0.951309\n",
       "1         199  0.048691"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total records in the training dataset\n",
    "training_records = train.shape[0]\n",
    "print('There are {:,} records in the training dataset.'.format(training_records))\n",
    "\n",
    "train_summary = pd.DataFrame(train.groupby('stroke').size()).rename(columns={0:'Count'})\n",
    "train_summary['Percent'] = train_summary['Count']/training_records\n",
    "train_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,022 records in the test dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>972</td>\n",
       "      <td>0.951076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.048924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count   Percent\n",
       "stroke                 \n",
       "0         972  0.951076\n",
       "1          50  0.048924"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total records in the test dataset\n",
    "test_records = test.shape[0]\n",
    "print('There are {:,} records in the test dataset.'.format(test_records))\n",
    "\n",
    "test_summary = pd.DataFrame(test.groupby('stroke').size()).rename(columns={0:'Count'})\n",
    "test_summary['Percent'] = test_summary['Count']/test_records\n",
    "test_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80.0% of all records in training dataset.\n"
     ]
    }
   ],
   "source": [
    "#Confirm the split did what you expected!\n",
    "print('There are {:.1%} of all records in training dataset.'.format(training_records/total_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Tune Models Using Validation Data\n",
    "So, now you have your training dataset and you know what metric to use to evaluate your model.  But how can you tune a model to ensure it is the best algorithm and best settings for your dataset?  You *could* use the true positive rate for the training dataset, but overreliance on the training dataset may create blindspots in your model where there is real combinations of predictors that due to limited data or simple bad luck were never seen in your training data.  \n",
    "\n",
    "How about the test data?  This is not a good idea because you want to keep the test data separate from the model evaluation/tuning process while building the model.  If you use the test dataset during model training and evaluation, the test dataset will no longer represent \"unseen\" data, which is import to evaluate how your model generalizes.\n",
    "\n",
    "So what can you do?  The answer is validation data.  This is *another* split of the data, this time using the training dataset.\n",
    "\n",
    "Using the training dataset, you can again use the *train_test_split* function to create two new datasets:\n",
    " * train_final: The final dataset used to train your models\n",
    " * validation: The dataset used to evaluate and tune your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data into training/validation data using a 75%/25% split\n",
    "#Be sure to use stratified sampling!\n",
    "train_final, validation = train_test_split(train, train_size = 0.75, stratify = train['stroke'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can finally built a binary classification model to predict strokes.  \n",
    "\n",
    "You will be using the [K-Nearest Neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) to build your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the training dataset is 13.423%.\n"
     ]
    }
   ],
   "source": [
    "#Import KNN model function from scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Remove 'id' and 'stroke' column from features (predictors)\n",
    "features = ~train_final.columns.isin(['id','gender','ever_married','work_type','Residence_type','smoking_status','stroke'])\n",
    "feature_columns = train_final.columns[features]\n",
    "model.fit(train_final[feature_columns],train_final['stroke'])\n",
    "\n",
    "\n",
    "#Import true positive rate (recall) function\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Predict output for training dataset\n",
    "train_predict = model.predict(train_final[feature_columns])\n",
    "\n",
    "tpr_train = recall_score(train_final['stroke'],train_predict)\n",
    "print('The true positive rate for the training dataset is {:.3%}.'.format(tpr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the validation dataset is 0.000%.\n"
     ]
    }
   ],
   "source": [
    "#Predict output for validation dataset\n",
    "validation_predict = model.predict(validation[feature_columns])\n",
    "\n",
    "tpr_validation = recall_score(validation['stroke'],validation_predict)\n",
    "print('The true positive rate for the validation dataset is {:.3%}.'.format(tpr_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model performs significantly worse in predicting strokes for the validation dataset than on the training dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "Instead of using a single static validation dataset, you can try cross-validation.  [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) splits the training dataset into *k* folds, and then creates a temporary training dataset consisting of *k-1* folds to build a model.  The process is repeated *k* times, holding a different fold of the training data out each time.  Then the validation metric is averaged across all *k* models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 5, 10, 15, 100],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#KNN parameters to test\n",
    "parameters = {'n_neighbors': [1,2,5,10,15,100], 'weights': ['uniform','distance']}\n",
    "\n",
    "#Initialize model\n",
    "knn = KNeighborsClassifier()\n",
    "#Set up a grid search for the best hyperparameters using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(knn, parameters, cv=5, scoring='recall')\n",
    "#Fit model using the full training\n",
    "grid_search.fit(train[feature_columns],train['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CV true positive rate from the grid search was 16.603%.\n"
     ]
    }
   ],
   "source": [
    "#Show the best true positive rate results of the grid search\n",
    "print('The best CV true positive rate from the grid search was {:.3%}.'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the best model parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Evaluate the Best Model on Unseen Data\n",
    "Finally, you can see how well your \"best\" model predicts strokes for the test dataset.  This is how you simulate how well your model will do in the real-world against totally new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the training dataset is 100.0%.\n"
     ]
    }
   ],
   "source": [
    "#Build your \"best\" model using the best parameters from the grid search\n",
    "knn_best = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "knn_best.fit(train[feature_columns],train['stroke'])\n",
    "\n",
    "#Calculate training true positive rate\n",
    "training_predict = knn_best.predict(train[feature_columns])\n",
    "training_tpr = recall_score(train['stroke'], training_predict)\n",
    "\n",
    "print('The true positive rate for the training dataset is {:.1%}.'.format(training_tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model performs perfectly on the training dataset!  Whenever you see a perfect training score, you should be skeptical.  It is very likely that you are dealing with [overfitting](https://en.wikipedia.org/wiki/Overfitting), where the model learned the training dataset TOO well.  This generally means that the model will not generalize well when compared to real world data.\n",
    "\n",
    "So now you can use this same model to predict strokes using the test dataset and see how the true positive rate compares to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the test dataset is 6.0%.\n"
     ]
    }
   ],
   "source": [
    "#Calculate test true positive rate\n",
    "test_predict = knn_best.predict(test[feature_columns])\n",
    "test_tpr = recall_score(test['stroke'], test_predict)\n",
    "\n",
    "print('The true positive rate for the test dataset is {:.1%}.'.format(test_tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
